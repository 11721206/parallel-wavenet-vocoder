test:
  train:
    batch_size: 1
    data_path: '/data/private/vc/datasets/arctic/slt/arctic_a0001.wav'
    steps_per_epoch: 1
    num_gpu: 1
  generate:
    data_path: '/data/private/vc/datasets/arctic/slt/arctic_a0001.wav'
    every_n_epoch: 1
l2/min:
  model:
    dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
    filter_width: 2
    residual_channels: 32
    dilation_channels: 32
    quantization_channels: 64
    skip_channels: 64
    condition_channels: 32
    use_biases: True
    n_iaf: 3
    normalize: True
  train:
    lr: 0.00005
l2/iaf4:
  model:
    dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
    filter_width: 2
    residual_channels: 32
    dilation_channels: 32
    quantization_channels: 64
    skip_channels: 64
    condition_channels: 32
    use_biases: True
    n_iaf: 4
    normalize: True
  train:
    lr: 0.0001
l2/iaf4_default:
  train:
    lr: 0.0002
l2/iaf5:
  model:
    n_iaf: 5
l2/iaf5_tran:
  model:
    n_iaf: 5
    cond_upsample_method: 'transposed_conv'
l2/iaf5_power:
  model:
    n_iaf: 5
  train:
    weight_power_loss: 0.0005
l2/iaf5_1x1conv:
  model:
    n_iaf: 5
mol/iaf5:
  model:
    n_iaf: 5
  train:
    batch_size: 8
    num_gpu: 8
    loss: 'mol'
    steps_per_epoch: 100
l2/iaf4_power:
  model:
    n_iaf: 4
  train:
    steps_per_epoch: 100
    weight_power_loss: 0.0005
sanity/mol:
  train:
    batch_size: 1
    data_path: '/data/private/vc/datasets/arctic/slt/arctic_a0001.wav'
    steps_per_epoch: 10
    num_gpu: 4
    loss: 'mol'
  generate:
    data_path: '/data/private/vc/datasets/arctic/slt/arctic_a0001.wav'
logistic/iaf4:
  model:
    n_iaf: 4
logistic/iaf5:
  model:
    n_iaf: 5
logistic/iaf5_power:
  model:
    n_iaf: 5
  train:
    weight_power_loss: 0.0005
    num_gpu: 4
logistic/iaf4_dil2:
  model:
    dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512,
                1, 2, 4, 8, 16, 32, 64, 128, 256, 512]
    n_iaf: 4
logistic/not_shared:
  model:
    n_iaf: 4
  train:
    batch_size: 4
logistic/h256:
  model:
    n_iaf: 4
#    dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256]
    quantization_channels: 256
  train:
    batch_size: 4
    num_gpu: 4
logistic/no_quan:
  model:
    n_iaf: 4
  train:
    batch_size: 4
    num_gpu: 8
logistic/no_norm:
  model:
    n_iaf: 4
    normalize: 'none'
  train:
    batch_size: 4
    num_gpu: 4
logistic/bn:
  model:
    n_iaf: 4
    normalize: 'bn'
  train:
    batch_size: 4
    num_gpu: 4
logistic/lj:
  model:
    n_iaf: 4
  train:
    batch_size: 4
    num_gpu: 8
    data_path: '/data/public/rw/LJSpeech-1.0_processed/*.wav'
  generate:
    data_path: '/data/public/rw/LJSpeech-1.0_processed/*.wav'
logistic/large:
  signal:
      max_length: 8000
  model:
      residual_channels: 64
      dilation_channels: 64
      use_biases: True
      n_iaf: 6
  train:
    batch_size: 8
    num_gpu: 4
logistic/large_tran:
  signal:
      max_length: 8000
  model:
      residual_channels: 64
      dilation_channels: 64
      use_biases: True
      n_iaf: 6
      cond_upsample_method: 'transposed_conv'
  train:
    batch_size: 8
    num_gpu: 4
logistic/no_skip:
  model:
    n_iaf: 4
    use_skip_connection: False
  train:
    batch_size: 4
    num_gpu: 8
